---
title: "Reply All Text Analysis"
author: "Noah Landesberg"
date: "3/17/2018"
output: html_document
---

One of my favorite podcasts is [Reply All](https://www.gimletmedia.com/reply-all), a show (roughly) about technology and the internet. It is  hosted by PJ Vogt and Alex Goldman, as well as some fantastic reporters and produecers who contribute regularily, and tells some of the most fasincating stories about the way we interact with technology. 

The show has been in production since 2014, and for a time felt like a great little secret, but their website now indicates that the show is downloaded "around 3.5 million times per month." If you haven't listened, I'd highly recomend checking it out. Some of my favorite episodes are (in no particular order):

* [The Cathedral](https://www.gimletmedia.com/reply-all/50-the-cathedral#episode-player)  
* [Boy in Photo](https://www.gimletmedia.com/reply-all/79-boy-in-photo#episode-player)  
* [The Grand Tapestry of Pepe](https://www.gimletmedia.com/reply-all/77-the-grand-tapestry-of-pepe#episode-player)  
* [Shine on You Crazy Goldman](https://www.gimletmedia.com/reply-all/44-shine-on-you-crazy-goldman#episode-player)  
* [Long Distance pt.1](https://www.gimletmedia.com/reply-all/long-distance#episode-player) and [Long Distance pt.2](https://www.gimletmedia.com/reply-all/103-long-distance-part-ii#episode-player)  
* [Zardulu](https://www.gimletmedia.com/reply-all/zardulu#episode-player)  

```{r load-packages, message = FALSE}
library(rvest) # for web scraping
library(dplyr) # for data tidying
library(stringr) # for working with strings
library(tidytext) # analyze text data!
library(ggplot2) # make nice plots
library(scales) # make plots even nicer
library(tidyr) # for data organization
library(purrr) # for iteration
```

To start, we will pull up a webpage with all episodes of Reply All
```{r set-base-url}
reply_all_url <- "https://www.gimletmedia.com/reply-all/all#all-episodes-list"
```

We will use some functions from `rvest` to make web scraping nice and easy. 
```{r get-episode-links}
episode_links <- reply_all_url %>%
  read_html() %>% # read HTML from page
  html_nodes("a") %>% # look for 'anchor' html tag <a>
  html_attr("href") %>% # get the href attribute from the tag, which is where the hyperlink is stored
  tibble(link = .) # put the data in a tibble with the variable episode

episode_links
```
Clean out 'bad' episode names that are not relevant.

```{r clean-episode-links}
episode_links <- episode_links %>%
  filter(
    str_detect(link, "#episode-player"), # must link to an epsiode player
    !str_detect(link, "re-broadcast"), # no re-broadcasts
    !str_detect(link, "rebroadcast"), # or rebroadcasts
    !str_detect(link, "revisited"), # or revisits
    !str_detect(link, "-2#episode-player"), # or other rebroadcasts
    !str_detect(link, "presents"), # or presentations of other shows
    !str_detect(link, "introducing"), # or introductions of other shows
    !str_detect(link, "updated"), # or updated versions of old episodes
    link != "/reply-all/6-this-proves-everything#episode-player" # sneaky update of an old episode
  ) %>%
  distinct() # and after all of that, no duplicates

episode_links <- episode_links %>% 
  mutate(episode_number = nrow(episode_links) + 1 - row_number()) # add in the episode number

head(episode_links)
```

Now get the full link to the episode (including the gimletmedia.com part)
```{r get-full-episode-link}
ep_data <- episode_links %>%
  mutate(
    full_link = paste0("https://www.gimletmedia.com", link)
  )

head(ep_data)
```

Write a function to get the transcript from an epsiode link
```{r}
getTranscript <- function(episode_link) {
  
  # This print statement helps us to understand the progress of the 
  # function when it is running.
  print(episode_link) 

  # Get the transcript from the webpage using the CSS node '.episode-transcript'
  transcript <- episode_link %>%
    read_html() %>%
    html_nodes(".episode-transcript") %>%
    html_text()

  episode_text <- data_frame(unlist(strsplit(transcript, "[^.a-z]+:", perl = T))) %>% setNames("text")
  
  episode_text <- episode_text %>% 
    mutate(
      text = trimws(text) # remove leading and trailing white-space
    ) %>%
    filter(
      tolower(text) != "transcript\n        ", # get rid of line indicating start of transcript
      tolower(text) != "transcript", # or this type of line indicating the start of transcript,
      tolower(text) != "[theme music", # get rid of Theme (or theme music)
      tolower(text) != "[intro music", # get rid of Intro Music (or intro music)
      tolower(text) != "transcript\n        [intro music", # or a mix of things
      tolower(text) != "transcript\n        [theme music" # or a different mix of things
    )

  # Ok this is gross, but handling some specific episodes where the transcript is not entered in a consistant way
  if (episode_link == "https://www.gimletmedia.com/reply-all/79-boy-in-photo#episode-player") {
    speaker <- rbind(
      "PJ", 
      data.frame(gsubfn::strapply(transcript, "[^.a-z]+:", c, perl = TRUE), stringsAsFactors = FALSE) %>% setNames("speaker")
    )
  } else if (episode_link == "https://www.gimletmedia.com/reply-all/52-raising-the-bar#episode-player") {
    speaker <- rbind(
      "PJ", 
      data.frame(gsubfn::strapply(transcript, "[^.a-z]+:", c, perl = TRUE), stringsAsFactors = FALSE) %>% setNames("speaker")
    )    
    episode_text <- episode_text %>% mutate(text = str_replace_all(text, "Transcript\n        PJ Vogt: ", ""))
  } else if (episode_link == "https://www.gimletmedia.com/reply-all/31-bonus-the-reddit-implosion-explainer#episode-player") {
    speaker <- rbind(
      "PJ", 
      data.frame(gsubfn::strapply(transcript, "[^.a-z]+:", c, perl = TRUE), stringsAsFactors = FALSE) %>% setNames("speaker")
    )
  } else if (episode_link == "https://www.gimletmedia.com/reply-all/2-instagram-for-doctors#episode-player") {
    speaker <- rbind(
      "PJ", 
      data.frame(gsubfn::strapply(transcript, "[^.a-z]+:", c, perl = TRUE), stringsAsFactors = FALSE) %>% setNames("speaker")
    )
    episode_text <- episode_text %>% mutate(text = str_replace_all(text, fixed("Transcript\n        [THEME SONG]PJ Vogt: "), ""))
  } else {
    speaker <- gsubfn::strapply(transcript, "[^.a-z]+:", c, perl = TRUE) %>% setNames("speaker")
  }

  transcript_clean <- data.frame(episode_text, speaker) %>%
    mutate(
      speaker = trimws(speaker),
      speaker = str_replace_all(speaker, "[^A-Z ]", ""),
      speaker = str_replace_all(speaker, "THEME MUSIC", ""),
      speaker = str_replace_all(speaker, "RING", ""),
      speaker = str_replace_all(speaker, "MUSIC", ""),
      speaker = str_replace_all(speaker, "BREAK", "")
    )

  # do some light cleaning of the transcript
  transcript_new <- transcript_clean %>%
    mutate(
      linenumber = row_number() # get the line number (1 is the first line, 2 is the second, etc.)
    ) %>%
    select(speaker, text, linenumber)

  # convert normal boring text into exciting cool tidy text
  transcript_tidy <- transcript_new %>%
    unnest_tokens(word, text)

  return(transcript_tidy)
}
```

```{r get-all-transcripts}
# use purrr to map the 'getTranscript' function over all of the URLs in the ep_data data frame
# takes ~3 minutes to run (depending on the speed of your internet connection)
ep_data <- ep_data %>%
  mutate(
    transcript = map(full_link, getTranscript)
  )

# unnest the resuls into one big data frame
tidy_ep_data <- ep_data %>%
  unnest(transcript)

head(tidy_ep_data)
```

```{r}
# turn missing values to NA and then fill using 
# the na.locf (last observation carried forward) function from the 'zoo' package
tidy_ep_data <- tidy_ep_data %>% 
  mutate(
    speaker = if_else(speaker == "", NA_character_, speaker),
    speaker = zoo::na.locf(speaker)
  )

# get the list of speakers clean
tidy_ep_data_clean <- tidy_ep_data %>%
  filter(
    !grepl("CREDIT", speaker), # remove credit chit-chat
    !grepl("AD ", speaker), # remove ad chit-chat
    !grepl("THEME", speaker), # remove theme chit-chat
    speaker != "ADPJ",
    speaker != "ADALEX",
    speaker != "OUTPJ",
    speaker != "OUTALEX"
  ) %>% 
  mutate(
    speaker = trimws(speaker),
    speaker = case_when(
      speaker == "ALEX" ~ "ALEX GOLDMAN",
      speaker == "REPLY ALL ALEX GOLDMAN" ~ "ALEX GOLDMAN",
      speaker == "GOLDMAN" ~ "ALEX GOLDMAN",
      speaker == "AG" ~ "ALEX GOLDMAN",
      speaker == "PJ" ~ "PJ VOGT",
      speaker == "REPLY ALL PJ VOGT" ~ "PJ VOGT",
      speaker == "BLUMBERG" ~ "ALEX BLUMBERG",
      speaker == "AB" ~ "ALEX BLUMBERG",
      speaker == "SRUTHI" ~ "SRUTHI PINNAMANENI",
      TRUE ~ speaker
    )
  )
```

```{r}
head(tidy_ep_data_clean)
```
